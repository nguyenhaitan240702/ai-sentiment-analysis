# AI Sentiment Analysis - Production Grade

Há»‡ thá»‘ng phÃ¢n tÃ­ch cáº£m xÃºc (sentiment analysis) cho tiáº¿ng Viá»‡t vá»›i kháº£ nÄƒng má»Ÿ rá»™ng Ä‘a ngÃ´n ngá»¯. Kiáº¿n trÃºc microservices vá»›i FastAPI, Celery workers, Redis cache, MongoDB document store vÃ  MySQL analytics.

## ğŸ—ï¸ Kiáº¿n trÃºc

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚    â”‚   Celery    â”‚    â”‚   Models    â”‚
â”‚     API     â”‚â”€â”€â”€â–¶â”‚   Worker    â”‚â”€â”€â”€â–¶â”‚ Rule/Trans/ â”‚
â”‚             â”‚    â”‚             â”‚    â”‚     LLM     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Redis    â”‚    â”‚  MongoDB    â”‚    â”‚   MySQL     â”‚
â”‚   (Cache)   â”‚    â”‚ (Documents) â”‚    â”‚ (Analytics) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Khá»Ÿi cháº¡y nhanh

### Development (Local)
```bash
# Clone vÃ  setup
git clone <repo-url>
cd ai-sentiment

# Táº¡o file mÃ´i trÆ°á»ng
cp .env.example .env

# Khá»Ÿi cháº¡y táº¥t cáº£ services
docker compose up -d --build

# Kiá»ƒm tra health
curl http://localhost:8080/healthz

# Test sentiment analysis
curl -X POST http://localhost:8080/v1/sentiment \
  -H "Content-Type: application/json" \
  -d '{"text": "TÃ´i ráº¥t thÃ­ch sáº£n pháº©m nÃ y!"}'
```

### Production
```bash
# Cháº¡y production stack
docker compose -f docker-compose.prod.yml up -d --build

# Scale workers
docker compose up -d --scale worker=3
```

## ğŸ“Š API Endpoints

### Health Check
```bash
GET /healthz
Response: {"status": "healthy", "version": "1.0.0"}
```

### Sentiment Analysis
```bash
POST /v1/sentiment
{
  "text": "TÃ´i ráº¥t hÃ i lÃ²ng vá»›i dá»‹ch vá»¥ nÃ y!",
  "lang": "vi"  // optional, auto-detect if not provided
}

Response:
{
  "label": "positive",
  "score": 0.85,
  "model": "rule_based_vi",
  "latency_ms": 15,
  "cached": false,
  "language_detected": "vi"
}
```

### Batch Processing
```bash
POST /v1/sentiment/batch
{
  "items": [
    {"id": "1", "text": "Tuyá»‡t vá»i!", "lang": "vi"},
    {"id": "2", "text": "KhÃ´ng hÃ i lÃ²ng", "lang": "vi"}
  ],
  "async": false
}

# Async batch
POST /v1/sentiment/batch
{
  "items": [...],
  "async": true
}
Response: {"job_id": "job_123", "status": "processing"}

# Check job status
GET /v1/jobs/job_123
```

## ğŸ”§ Cáº¥u hÃ¬nh Models

### Rule-based (Default - Nhanh, nháº¹)
```bash
MODEL_BACKEND=rule
```
- Sá»­ dá»¥ng lexicon tiáº¿ng Viá»‡t + underthesea
- Latency: ~10-50ms
- RAM: ~100MB

### Transformer (ChÃ­nh xÃ¡c cao)
```bash
MODEL_BACKEND=transformer
MODEL_NAME=vinai/phobert-base
```
- Sá»­ dá»¥ng PhoBERT hoáº·c mBERT
- Latency: ~100-500ms
- RAM: ~1-2GB
- Cáº§n GPU cho tá»‘c Ä‘á»™ tá»‘i Æ°u

### LLM (Linh hoáº¡t nháº¥t)
```bash
MODEL_BACKEND=llm
LLM_API_URL=http://localhost:11434/api/generate
LLM_MODEL_NAME=llama2-vietnamese
```
- Káº¿t ná»‘i LLM API (Ollama, OpenAI-compatible)
- Latency: ~1-5s
- CÃ³ fallback vá» rule-based khi lá»—i

## ğŸ“ˆ Scaling & Production

### Horizontal Scaling
```bash
# Scale API instances
docker compose up -d --scale api=3

# Scale workers
docker compose up -d --scale worker=5

# Docker Swarm mode
docker stack deploy -c swarm-stack.yml ai-sentiment
```

### Monitoring
- Prometheus metrics: `http://localhost:9090`
- Grafana dashboard: `http://localhost:3000`
- Logs: JSON structured, centralized

### Performance Tuning
```bash
# TÄƒng worker concurrency
CELERY_WORKER_CONCURRENCY=4

# TÄƒng cache TTL
CACHE_TTL=3600

# Batch size optimization
BATCH_MAX=256
```

## ğŸ—„ï¸ Database Schema

### MongoDB Collections
```javascript
// texts
{
  "_id": ObjectId,
  "source": "api",
  "lang": "vi",
  "content": "Text content",
  "content_hash": "sha256_hash",
  "created_at": ISODate
}

// inferences
{
  "_id": ObjectId,
  "text_id": ObjectId,
  "model_name": "rule_based_vi",
  "version": "1.0",
  "sentiment": {"label": "positive", "score": 0.85},
  "tokens_metadata": {...},
  "latency_ms": 15,
  "created_at": ISODate
}
```

### MySQL Tables
```sql
-- BÃ¡o cÃ¡o hÃ ng ngÃ y
CREATE TABLE sentiments_daily (
    date DATE,
    lang VARCHAR(5),
    source VARCHAR(50),
    pos_cnt INT DEFAULT 0,
    neu_cnt INT DEFAULT 0,
    neg_cnt INT DEFAULT 0,
    avg_score DECIMAL(3,2),
    last_updated TIMESTAMP,
    PRIMARY KEY (date, lang, source)
);
```

## ğŸ§ª Testing

```bash
# Cháº¡y táº¥t cáº£ tests
make test

# Test coverage
make test-coverage

# Integration tests
make test-integration

# Load testing
make bench
```

## ğŸ”’ Báº£o máº­t

- Environment variables cho secrets
- Rate limiting (100 req/min máº·c Ä‘á»‹nh)
- Input validation & sanitization
- Non-root containers
- Read-only filesystems

## ğŸ“ Development

### Setup mÃ´i trÆ°á»ng dev
```bash
# Python virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Pre-commit hooks
pre-commit install

# Run locally
make dev
```

### Code Quality
```bash
# Linting
make lint

# Format code
make format

# Type checking
make typecheck
```

## ğŸŒ Multi-language Support

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ má»Ÿ rá»™ng:
- Vietnamese (primary) - underthesea, pyvi
- English - VADER, TextBlob
- Auto language detection - fasttext

ThÃªm ngÃ´n ngá»¯ má»›i:
1. Táº¡o model adapter trong `core/models/`
2. ThÃªm lexicon trong `data/lexicons/`
3. Cáº­p nháº­t language detection

## âš¡ Performance Benchmarks

| Model Type | Latency (p95) | Throughput | Memory |
|------------|---------------|------------|---------|
| Rule-based | 50ms | 2000 req/s | 100MB |
| Transformer | 200ms | 500 req/s | 1.5GB |
| LLM | 2s | 50 req/s | 8GB |

## ğŸ›Ÿ Troubleshooting

### Common Issues

1. **Model loading failed**
   ```bash
   # Check model files
   docker exec -it ai-sentiment-api ls -la /app/models/
   
   # Verify model backend
   echo $MODEL_BACKEND
   ```

2. **Database connection errors**
   ```bash
   # Check service health
   docker compose ps
   
   # Check logs
   docker compose logs mongo
   docker compose logs mysql
   ```

3. **High memory usage**
   - Switch to rule-based model
   - Reduce batch size
   - Enable model quantization

### Logs & Debugging
```bash
# API logs
docker compose logs -f api

# Worker logs
docker compose logs -f worker

# All services
docker compose logs -f
```

## ğŸ“„ License

MIT License - see LICENSE file for details.

## ğŸ¤ Contributing

1. Fork repository
2. Create feature branch
3. Add tests for new features
4. Ensure all tests pass
5. Submit pull request

---

**Built with â¤ï¸ for Vietnamese NLP community**
