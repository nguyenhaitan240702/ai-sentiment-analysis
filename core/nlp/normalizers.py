"""
Vietnamese text normalizers for AI Sentiment Analysis
Handles Unicode normalization, TELEX conversion, emoji processing
"""

import re
import unicodedata
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)

class VietnameseNormalizer:
    """Vietnamese text normalizer"""

    def __init__(self):
        # TELEX to Unicode mapping
        self.telex_map = {
            'aa': 'Ã¢', 'aw': 'Äƒ', 'ee': 'Ãª', 'oo': 'Ã´', 'ow': 'Æ¡', 'uw': 'Æ°',
            'dd': 'Ä‘', 'Aa': 'Ã‚', 'Aw': 'Ä‚', 'Ee': 'ÃŠ', 'Oo': 'Ã”', 'Ow': 'Æ ',
            'Uw': 'Æ¯', 'Dd': 'Ä', 'DD': 'Ä'
        }

        # Tone marks
        self.tone_map = {
            'as': 'Ã¡', 'af': 'Ã ', 'ar': 'áº£', 'ax': 'Ã£', 'aj': 'áº¡',
            'es': 'Ã©', 'ef': 'Ã¨', 'er': 'áº»', 'ex': 'áº½', 'ej': 'áº¹',
            'is': 'Ã­', 'if': 'Ã¬', 'ir': 'á»‰', 'ix': 'Ä©', 'ij': 'á»‹',
            'os': 'Ã³', 'of': 'Ã²', 'or': 'á»', 'ox': 'Ãµ', 'oj': 'á»',
            'us': 'Ãº', 'uf': 'Ã¹', 'ur': 'á»§', 'ux': 'Å©', 'uj': 'á»¥',
            'ys': 'Ã½', 'yf': 'á»³', 'yr': 'á»·', 'yx': 'á»¹', 'yj': 'á»µ'
        }

        # Common emoji patterns
        self.emoji_pattern = re.compile(
            "["
            "\U0001F600-\U0001F64F"  # emoticons
            "\U0001F300-\U0001F5FF"  # symbols & pictographs
            "\U0001F680-\U0001F6FF"  # transport & map
            "\U0001F1E0-\U0001F1FF"  # flags
            "\U00002702-\U000027B0"
            "\U000024C2-\U0001F251"
            "]+", flags=re.UNICODE
        )

        # Vietnamese slang/abbreviation mappings
        self.slang_map = {
            'k': 'khÃ´ng',
            'ko': 'khÃ´ng',
            'dc': 'Ä‘Æ°á»£c',
            'Ä‘c': 'Ä‘Æ°á»£c',
            'vs': 'vá»›i',
            'w': 'vá»›i',
            'r': 'rá»“i',
            'ms': 'má»›i',
            'nx': 'ná»¯a',
            'ntn': 'nhÆ° tháº¿ nÃ o',
            'sao': 'sao',
            'ok': 'Ä‘Æ°á»£c',
            'oke': 'Ä‘Æ°á»£c',
            'tks': 'cáº£m Æ¡n',
            'thanks': 'cáº£m Æ¡n',
            'ty': 'cáº£m Æ¡n',
            'nÃ³': 'nÃ³',
            'Ã´ng': 'Ã´ng',
            'bÃ ': 'bÃ ',
            'thg': 'tháº±ng',
            'Ä‘á»©a': 'Ä‘á»©a',
            'kg': 'khÃ´ng',
            'kh': 'khÃ´ng',
            'cx': 'cÅ©ng',
            'bh': 'bÃ¢y giá»',
            'h': 'giá»',
            'lm': 'lÃ m',
            'záº­y': 'váº­y',
            'z': 'gÃ¬',
            'j': 'gÃ¬',
            'wtf': 'gÃ¬ tháº¿',
            'omg': 'Ã´i'
        }

    async def normalize(self, text: str) -> str:
        """Normalize Vietnamese text"""
        if not text:
            return ""

        # Unicode normalization (NFC)
        text = unicodedata.normalize('NFC', text)

        # Convert TELEX to Unicode
        text = self._convert_telex(text)

        # Process emojis (convert to text or remove)
        text = self._process_emojis(text)

        # Expand Vietnamese slang
        text = self._expand_slang(text)

        # Clean whitespace
        text = re.sub(r'\s+', ' ', text.strip())

        # Optional: convert to lowercase (preserving Vietnamese characters)
        text = text.lower()

        return text

    def _convert_telex(self, text: str) -> str:
        """Convert TELEX input to Unicode Vietnamese"""
        # Sort by length (longer first) to avoid conflicts
        sorted_telex = sorted(self.telex_map.items(), key=lambda x: len(x[0]), reverse=True)

        for telex, unicode_char in sorted_telex:
            text = text.replace(telex, unicode_char)

        # Handle tone marks
        for tone, char in self.tone_map.items():
            text = text.replace(tone, char)

        return text

    def _process_emojis(self, text: str) -> str:
        """Process emojis - convert to sentiment indicators or remove"""
        # Simple emoji to sentiment mapping
        emoji_sentiment_map = {
            'ðŸ˜Š': ' tÃ­ch cá»±c ',
            'ðŸ˜': ' thÃ­ch ',
            'ðŸ˜‚': ' vui ',
            'ðŸ˜­': ' buá»“n ',
            'ðŸ˜¡': ' tá»©c giáº­n ',
            'ðŸ˜”': ' buá»“n ',
            'ðŸ‘': ' tá»‘t ',
            'ðŸ‘Ž': ' khÃ´ng tá»‘t ',
            'â¤ï¸': ' yÃªu ',
            'ðŸ’”': ' buá»“n ',
            'ðŸ”¥': ' tuyá»‡t vá»i ',
            'ðŸ’¯': ' hoÃ n háº£o '
        }

        # Replace known emojis with sentiment words
        for emoji, sentiment in emoji_sentiment_map.items():
            text = text.replace(emoji, sentiment)

        # Remove remaining emojis
        text = self.emoji_pattern.sub(' ', text)

        return text

    def _expand_slang(self, text: str) -> str:
        """Expand Vietnamese internet slang"""
        words = text.split()
        expanded_words = []

        for word in words:
            # Check if word is slang
            lower_word = word.lower()
            if lower_word in self.slang_map:
                expanded_words.append(self.slang_map[lower_word])
            else:
                expanded_words.append(word)

        return ' '.join(expanded_words)
